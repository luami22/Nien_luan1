{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv8 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d07a3d-a4b0-43a5-fb8d-c2dca0173f97"
      },
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.6 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete ✅ (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66c50e2b-d086-4b8e-f14e-0517b5bbd05c"
      },
      "source": [
        "# Run inference on an image with YOLOv8n\n",
        "!yolo predict model=/content/runs/detect/train8/weights/best.pt source='https://cdn2.cellphones.com.vn/insecure/rs:fill:0:0/q:80/plain/https://cellphones.com.vn/media/wysiwyg/May-tinh-cam-tay/Casio/may-tinh-casio-4.jpg'"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.6 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\n",
            "Downloading https://cdn2.cellphones.com.vn/insecure/rs:fill:0:0/q:80/plain/https://cellphones.com.vn/media/wysiwyg/May-tinh-cam-tay/Casio/may-tinh-casio-4.jpg to 'may-tinh-casio-4.jpg'...\n",
            "100% 77.9k/77.9k [00:00<00:00, 181kB/s]\n",
            "image 1/1 /content/may-tinh-casio-4.jpg: 384x640 1 maytinh, 103.8ms\n",
            "Speed: 3.6ms preprocess, 103.8ms inference, 581.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict11\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "# Train YOLOv8n on COCO8 for 3 epochs\n",
        "!yolo train model=yolov8n.pt data=maytinh16.yaml epochs=100 imgsz=640"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x /content/maytinh16.rar"
      ],
      "metadata": {
        "id": "E3AkpY0bl4E5",
        "outputId": "80c26d24-d971-487e-f2e8-a347c133b258",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 6.11 beta 1 freeware      Copyright (c) 1993-2022 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/maytinh16.rar\n",
            "\n",
            "Creating    maytinh16                                                 OK\n",
            "Creating    maytinh16/images                                          OK\n",
            "Creating    maytinh16/images/train                                    OK\n",
            "Extracting  maytinh16/images/train/face106070.jpg                        \b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face110463.jpg                        \b\b\b\b 12%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face116188.jpg                        \b\b\b\b 17%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face124423.jpg                        \b\b\b\b 24%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face126882.jpg                        \b\b\b\b 30%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face127987.jpg                        \b\b\b\b 36%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face135144.jpg                        \b\b\b\b 42%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face141983.jpg                        \b\b\b\b 49%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face151604.jpg                        \b\b\b\b 55%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face154470.jpg                        \b\b\b\b 61%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face181299.jpg                        \b\b\b\b 68%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face189317.jpg                        \b\b\b\b 74%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face190097.jpg                        \b\b\b\b 80%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face19075.jpg                         \b\b\b\b 87%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face19450.jpg                         \b\b\b\b 93%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/images/train/face197988.jpg                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Creating    maytinh16/labels                                          OK\n",
            "Creating    maytinh16/labels/train                                    OK\n",
            "Extracting  maytinh16/labels/train/classes.txt                           \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face106070.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face110463.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face116188.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face124423.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face126882.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face127987.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face135144.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face141983.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face151604.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face154470.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face181299.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face189317.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face190097.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face19075.txt                         \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face19450.txt                         \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "Extracting  maytinh16/labels/train/face197988.txt                        \b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
        "# model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
        "\n",
        "# Use the model\n",
        "results = model.train(data='/content/maytinh16.yaml', epochs=3)  # train the model\n",
        "results = model.val()  # evaluate model performance on the validation set\n",
        "results = model('/content/tai-nghe-sieu-nho-nguy-trang-may-tinh-cam-tay-Casio.jpg')  # predict on an image\n",
        "results = model.export(format='onnx')  # export the model to ONNX format"
      ],
      "metadata": {
        "id": "bpF9-vS_DAaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee7b2e02-d46c-4120-b4c3-a0658b10ba5b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.6 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.yaml, data=/content/maytinh16.yaml, epochs=3, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train10, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train10\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "YOLOv8n summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train10', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/maytinh16/labels/train.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/maytinh16/labels/train.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to runs/detect/train10/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train10\u001b[0m\n",
            "Starting training for 3 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        1/3      1.84G      3.528      4.004      4.273         50        640: 100%|██████████| 1/1 [00:00<00:00,  5.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         12         24    0.00167       0.25    0.00166   0.000443\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        2/3      1.81G      3.342      4.039      4.285         53        640: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         12         24    0.00346      0.583    0.00402    0.00131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "        3/3      1.81G      3.261      3.861      4.208         39        640: 100%|██████████| 1/1 [00:00<00:00,  5.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         12         24    0.00331      0.583    0.00331    0.00112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3 epochs completed in 0.010 hours.\n",
            "Optimizer stripped from runs/detect/train10/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train10/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train10/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.6 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00, 10.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         12         24    0.00346      0.583    0.00402    0.00131\n",
            "               maytinh         12         12    0.00418          1    0.00477    0.00146\n",
            "                 nguoi         12         12    0.00273      0.167    0.00327    0.00115\n",
            "Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train10\u001b[0m\n",
            "Ultralytics YOLOv8.1.6 🚀 Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/maytinh16/labels/train.cache... 12 images, 0 backgrounds, 0 corrupt: 100%|██████████| 12/12 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         12         24    0.00349      0.583    0.00357    0.00112\n",
            "               maytinh         12         12    0.00415          1    0.00433    0.00123\n",
            "                 nguoi         12         12    0.00282      0.167    0.00282    0.00101\n",
            "Speed: 0.2ms preprocess, 4.3ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train102\u001b[0m\n",
            "\n",
            "image 1/1 /content/tai-nghe-sieu-nho-nguy-trang-may-tinh-cam-tay-Casio.jpg: 640x480 (no detections), 15.9ms\n",
            "Speed: 4.5ms preprocess, 15.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Ultralytics YOLOv8.1.6 🚀 Python-3.10.12 torch-2.1.0+cu121 CPU (Intel Xeon 2.30GHz)\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs/detect/train10/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 6, 8400) (5.9 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
            "Collecting onnx>=1.12.0\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.7/15.7 MB 59.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 9.9s, installed 1 package: ['onnx>=1.12.0']\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 11.0s, saved as 'runs/detect/train10/weights/best.onnx' (11.7 MB)\n",
            "\n",
            "Export complete (13.0s)\n",
            "Results saved to \u001b[1m/content/runs/detect/train10/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=runs/detect/train10/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=runs/detect/train10/weights/best.onnx imgsz=640 data=/content/maytinh16.yaml  \n",
            "Visualize:       https://netron.app\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
        "model.train(data='coco128.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "8Go5qqS9LbC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Segmentation\n",
        "\n",
        "YOLOv8 _segmentation_ models use the `-seg` suffix, i.e. `yolov8n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n"
      ],
      "metadata": {
        "id": "7ZW58jUzK66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\n",
        "model.train(data='coco128-seg.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "WFPJIQl_L5HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Classification\n",
        "\n",
        "YOLOv8 _classification_ models use the `-cls` suffix, i.e. `yolov8n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n"
      ],
      "metadata": {
        "id": "ax3p94VNK9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
        "model.train(data='mnist160', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "5q9Zu6zlL5rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pose\n",
        "\n",
        "YOLOv8 _pose_ models use the `-pose` suffix, i.e. `yolov8n-pose.pt` and are pretrained on COCO Keypoints. See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for full details."
      ],
      "metadata": {
        "id": "SpIaFLiO11TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLOv8n-pose, train it on COCO8-pose for 3 epochs and predict an image with it\n",
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n-pose.pt')  # load a pretrained YOLOv8n classification model\n",
        "model.train(data='coco8-pose.yaml', epochs=3)  # train the model\n",
        "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
      ],
      "metadata": {
        "id": "si4aKFNg19vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEijrePND_2I"
      },
      "source": [
        "# Appendix\n",
        "\n",
        "Additional content below."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pip install from source\n",
        "!pip install git+https://github.com/ultralytics/ultralytics@main"
      ],
      "metadata": {
        "id": "pIdE6i8C3LYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone and run tests on updates branch\n",
        "!git clone https://github.com/ultralytics/ultralytics -b main\n",
        "%pip install -qe ultralytics"
      ],
      "metadata": {
        "id": "uRKlwxSJdhd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run tests (Git clone only)\n",
        "!pytest ultralytics/tests"
      ],
      "metadata": {
        "id": "GtPlh7mcCGZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validate multiple models\n",
        "for x in 'nsmlx':\n",
        "  !yolo val model=yolov8{x}.pt data=coco.yaml"
      ],
      "metadata": {
        "id": "Wdc6t_bfzDDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}